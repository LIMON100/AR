{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport pickle\nimport datetime\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom keras.models import Sequential, Input\nfrom keras import layers\nfrom keras.layers.core import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, \\\n                                       ZeroPadding2D,Conv2D\n\nfrom keras.utils import to_categorical\n\n\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom keras.models import model_from_json\n# from sklearn.metrics import log_loss\nfrom numpy.random import permutation\n\nimport keras\nimport keras.backend as K \nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Add, Input, BatchNormalization, Activation\nfrom keras.layers import  Conv2D, MaxPooling2D, AveragePooling2D, Flatten\nfrom keras.regularizers import l2\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport glob\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-10T09:59:50.32176Z","iopub.execute_input":"2021-06-10T09:59:50.322226Z","iopub.status.idle":"2021-06-10T09:59:50.338486Z","shell.execute_reply.started":"2021-06-10T09:59:50.32219Z","shell.execute_reply":"2021-06-10T09:59:50.337384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_rows = 224\nimg_cols = 224\ndf = pd.read_csv(\"../input/state-farm-distracted-driver-detection/driver_imgs_list.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T06:58:37.128914Z","iopub.execute_input":"2021-06-09T06:58:37.129349Z","iopub.status.idle":"2021-06-09T06:58:37.191144Z","shell.execute_reply.started":"2021-06-09T06:58:37.129303Z","shell.execute_reply":"2021-06-09T06:58:37.189841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(path, rows=None, cols=None, gray=True):\n    if gray:\n        img = cv2.imread(path,0)\n    else:\n        img = cv2.imread(path)\n    if rows != None and cols != None:\n        img = cv2.resize(img,(rows,cols))\n        #img = np.reshape(img, (rows, cols,1))\n    return img","metadata":{"execution":{"iopub.status.busy":"2021-06-09T06:58:37.193818Z","iopub.execute_input":"2021-06-09T06:58:37.194301Z","iopub.status.idle":"2021-06-09T06:58:37.203374Z","shell.execute_reply.started":"2021-06-09T06:58:37.194255Z","shell.execute_reply":"2021-06-09T06:58:37.202042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(split=0.33, rows=None, cols=None):\n    paths = glob.glob(os.path.join(\"../input/state-farm-distracted-driver-detection/imgs\", \"train\", \"*\",  \"*.jpg\"))\n    labels = [int(x.split('/')[5][1]) for x in paths]\n    if rows != None and cols != None:\n        images = [load_image(x, rows, cols,gray=False) for x in paths]\n    else:\n        images = [load_image(x, gray=False) for x in paths]\n    y = to_categorical(labels)\n    x_train, x_test, y_train, y_test = train_test_split(images, y, test_size=split)\n    \n    return np.array(x_train), np.array(x_test), y_train, y_test","metadata":{"execution":{"iopub.status.busy":"2021-06-09T06:58:37.205624Z","iopub.execute_input":"2021-06-09T06:58:37.206104Z","iopub.status.idle":"2021-06-09T06:58:37.216011Z","shell.execute_reply.started":"2021-06-09T06:58:37.206058Z","shell.execute_reply":"2021-06-09T06:58:37.214655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = load_data(rows=img_rows, cols=img_cols)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T06:58:37.21752Z","iopub.execute_input":"2021-06-09T06:58:37.218057Z","iopub.status.idle":"2021-06-09T07:03:13.21913Z","shell.execute_reply.started":"2021-06-09T06:58:37.218012Z","shell.execute_reply":"2021-06-09T07:03:13.217863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vgg_std16_model(img_rows, img_cols, color_type=3):\n    model = Sequential()\n    model.add(ZeroPadding2D((1, 1), input_shape=(img_rows, img_cols,color_type)))\n    model.add(Convolution2D(64, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(64, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(128, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(128, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(256, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(256, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(256, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1000, activation='softmax'))\n\n    #model.load_weights('../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n\n    # Code above loads pre-trained data and\n    model.layers.pop()\n    model.add(Dense(10, activation='softmax'))\n    # Learning rate is changed to 0.001\n    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:03:13.220797Z","iopub.execute_input":"2021-06-09T07:03:13.22123Z","iopub.status.idle":"2021-06-09T07:03:13.243661Z","shell.execute_reply.started":"2021-06-09T07:03:13.221173Z","shell.execute_reply":"2021-06-09T07:03:13.240443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main_block(x, filters, n, strides, dropout):\n\t# Normal part\n\tx_res = Conv2D(filters, (3,3), strides=strides, padding=\"same\")(x)# , kernel_regularizer=l2(5e-4)\n\tx_res = BatchNormalization()(x_res)\n\tx_res = Activation('relu')(x_res)\n\tx_res = Conv2D(filters, (3,3), padding=\"same\")(x_res)\n\t# Alternative branch\n\tx = Conv2D(filters, (1,1), strides=strides)(x)\n\t# Merge Branches\n\tx = Add()([x_res, x])\n\n\tfor i in range(n-1):\n\t\t# Residual conection\n\t\tx_res = BatchNormalization()(x)\n\t\tx_res = Activation('relu')(x_res)\n\t\tx_res = Conv2D(filters, (3,3), padding=\"same\")(x_res)\n\t\t# Apply dropout if given\n\t\tif dropout: x_res = Dropout(dropout)(x)\n\t\t# Second part\n\t\tx_res = BatchNormalization()(x_res)\n\t\tx_res = Activation('relu')(x_res)\n\t\tx_res = Conv2D(filters, (3,3), padding=\"same\")(x_res)\n\t\t# Merge branches\n\t\tx = Add()([x, x_res])\n\n\t# Inter block part\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\treturn x\n\ndef build_model(input_dims, output_dim, n, k, act= \"relu\", dropout=None):\n\t\"\"\" Builds the model. Params:\n\t\t\t- n: number of layers. WRNs are of the form WRN-N-K\n\t\t\t\t It must satisfy that (N-4)%6 = 0\n\t\t\t- k: Widening factor. WRNs are of the form WRN-N-K\n\t\t\t\t It must satisfy that K%2 = 0\n\t\t\t- input_dims: input dimensions for the model\n\t\t\t- output_dim: output dimensions for the model\n\t\t\t- dropout: dropout rate - default=0 (not recomended >0.3)\n\t\t\t- act: activation function - default=relu. Build your custom\n\t\t\t\t   one with keras.backend (ex: swish, e-swish)\n\t\"\"\"\n\t# Ensure n & k are correct\n\tassert (n-4)%6 == 0\n\tassert k%2 == 0\n\tn = (n-4)//6 \n\t# This returns a tensor input to the model\n\tinputs = Input(shape=(input_dims))\n\n\t# Head of the model\n\tx = Conv2D(16, (3,3), padding=\"same\")(inputs)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# 3 Blocks (normal-residual)\n\tx = main_block(x, 16*k, n, (1,1), dropout) # 0\n\tx = main_block(x, 32*k, n, (2,2), dropout) # 1\n\tx = main_block(x, 64*k, n, (2,2), dropout) # 2\n\t\t\t\n\t# Final part of the model\n\tx = AveragePooling2D((8,8))(x)\n\tx = Flatten()(x)\n\toutputs = Dense(output_dim, activation=\"softmax\")(x)\n\n\tmodel = Model(inputs=inputs, outputs=outputs)\n\treturn model","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:03:13.245509Z","iopub.execute_input":"2021-06-09T07:03:13.245993Z","iopub.status.idle":"2021-06-09T07:03:13.265021Z","shell.execute_reply.started":"2021-06-09T07:03:13.245948Z","shell.execute_reply":"2021-06-09T07:03:13.263619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:03:13.26845Z","iopub.execute_input":"2021-06-09T07:03:13.268928Z","iopub.status.idle":"2021-06-09T07:03:13.28334Z","shell.execute_reply.started":"2021-06-09T07:03:13.268881Z","shell.execute_reply":"2021-06-09T07:03:13.281856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = vgg_std16_model(img_rows=img_rows, img_cols=img_cols)\nmodel = build_model((224,224,3), 10,16,4)\nmodel.load_weights('../input/weight1/weights.h5')\nmodel.compile(\"adam\",\"categorical_crossentropy\", ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:03:13.285632Z","iopub.execute_input":"2021-06-09T07:03:13.286206Z","iopub.status.idle":"2021-06-09T07:03:16.291823Z","shell.execute_reply.started":"2021-06-09T07:03:13.28616Z","shell.execute_reply":"2021-06-09T07:03:16.290746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:03:16.293432Z","iopub.execute_input":"2021-06-09T07:03:16.293888Z","iopub.status.idle":"2021-06-09T07:03:16.341767Z","shell.execute_reply.started":"2021-06-09T07:03:16.29384Z","shell.execute_reply":"2021-06-09T07:03:16.340666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:03:16.345357Z","iopub.execute_input":"2021-06-09T07:03:16.345689Z","iopub.status.idle":"2021-06-09T07:03:55.52797Z","shell.execute_reply.started":"2021-06-09T07:03:16.345658Z","shell.execute_reply":"2021-06-09T07:03:55.52632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x_train, y_train, batch_size=16, epochs=5, validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:03:55.531313Z","iopub.execute_input":"2021-06-09T07:03:55.533945Z","iopub.status.idle":"2021-06-09T07:26:28.680955Z","shell.execute_reply.started":"2021-06-09T07:03:55.533888Z","shell.execute_reply":"2021-06-09T07:26:28.67948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(x_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:26:28.684727Z","iopub.execute_input":"2021-06-09T07:26:28.685214Z","iopub.status.idle":"2021-06-09T07:27:02.944626Z","shell.execute_reply.started":"2021-06-09T07:26:28.685166Z","shell.execute_reply":"2021-06-09T07:27:02.943585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"./model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"./weights.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:30:44.825855Z","iopub.execute_input":"2021-06-09T07:30:44.826282Z","iopub.status.idle":"2021-06-09T07:30:44.977123Z","shell.execute_reply.started":"2021-06-09T07:30:44.826247Z","shell.execute_reply":"2021-06-09T07:30:44.97582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ANOTHER PART(Driver Activity detection - PY)","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\n\nimport keras\nimport numpy\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:33:20.272154Z","iopub.execute_input":"2021-06-10T05:33:20.272628Z","iopub.status.idle":"2021-06-10T05:33:26.093448Z","shell.execute_reply.started":"2021-06-10T05:33:20.272511Z","shell.execute_reply":"2021-06-10T05:33:26.092242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nimport numpy\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:35:31.281023Z","iopub.execute_input":"2021-06-10T05:35:31.281413Z","iopub.status.idle":"2021-06-10T05:35:31.286714Z","shell.execute_reply.started":"2021-06-10T05:35:31.281383Z","shell.execute_reply":"2021-06-10T05:35:31.285152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n        rescale=1./255, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:35:32.477112Z","iopub.execute_input":"2021-06-10T05:35:32.477857Z","iopub.status.idle":"2021-06-10T05:35:32.486203Z","shell.execute_reply.started":"2021-06-10T05:35:32.477826Z","shell.execute_reply":"2021-06-10T05:35:32.482825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = '../input/state-farm-distracted-driver-detection/imgs/train'\ntest_data = '../input/state-farm-distracted-driver-detection/imgs/test'\ntrain_generator = train_datagen.flow_from_directory(\n        train_data,\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode='categorical',\n        subset='training')\n\nval_generator = train_datagen.flow_from_directory(\n        train_data,\n        target_size=(224,224),\n        batch_size=32,\n        class_mode='categorical',\n        subset='validation')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:35:33.98073Z","iopub.execute_input":"2021-06-10T05:35:33.981146Z","iopub.status.idle":"2021-06-10T05:35:42.277122Z","shell.execute_reply.started":"2021-06-10T05:35:33.981116Z","shell.execute_reply":"2021-06-10T05:35:42.275868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\nac_labels=  [\"c0: safe driving\",\n\"c1: texting - right\",\n\"c2: talking on the phone - right\",\n\"c3: texting - left\",\n\"c4: talking on the phone - left\",\n\"c5: operating the radio\",\n\"c6: drinking\",\n\"c7: reaching behind\",\n\"c8: hair and makeup\",\n\"c9: talking to passenger\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:35:42.279191Z","iopub.execute_input":"2021-06-10T05:35:42.279534Z","iopub.status.idle":"2021-06-10T05:35:42.288606Z","shell.execute_reply.started":"2021-06-10T05:35:42.279502Z","shell.execute_reply":"2021-06-10T05:35:42.287405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs, labels = next(train_generator)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:35:42.291758Z","iopub.execute_input":"2021-06-10T05:35:42.292286Z","iopub.status.idle":"2021-06-10T05:35:42.808193Z","shell.execute_reply.started":"2021-06-10T05:35:42.292227Z","shell.execute_reply":"2021-06-10T05:35:42.806534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import functools\n\ndef list_counts(start_dir):\n    lst = sorted(os.listdir(start_dir))\n    out = [(fil, len(os.listdir( os.path.join(start_dir, fil)))) for fil in lst if os.path.isdir(os.path.join(start_dir,fil))]\n    return out\n\nout = list_counts(train_data)\nlabels, counts = zip(*out)\nprint(\"Total number of images : \",functools.reduce(lambda a,b : a+b, counts))\nout","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:35:42.81383Z","iopub.execute_input":"2021-06-10T05:35:42.814257Z","iopub.status.idle":"2021-06-10T05:35:42.858329Z","shell.execute_reply.started":"2021-06-10T05:35:42.814216Z","shell.execute_reply":"2021-06-10T05:35:42.857354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\n# Pretty display for notebooks\n%matplotlib inline\n\n\ny = np.array(counts)\nwidth = 1/1.5\nN = len(y)\nx = range(N)\n\nfig = plt.figure(figsize=(20,15))\nay = fig.add_subplot(211)\n\nplt.xticks(x, labels, size=15)\nplt.yticks(size=15)\n\nay.bar(x, y, width, color=\"blue\")\n\nplt.title('Bar Chart',size=25)\nplt.xlabel('classname',size=15)\nplt.ylabel('Count',size=15)\n\nplt.show()\n\n\n\ndef showImages(imgs ,inlabels=None, single=True):\n    if single:\n        aim = (imgs * 255 ).astype(np.uint8)\n        img = Image.fromarray(aim)\n        if labels is not None:\n            print(\"Label : \", ac_labels[np.argmax(inlabels)])\n        plt.imshow(img)\n        plt.show()\n    else:\n        for i,img in enumerate(imgs):\n            lbl = None\n            if inlabels is not None:\n                lbl = labels[i]\n            showImages(img, lbl)\n\nind = 1\nshowImages(imgs[:ind], inlabels=labels[:ind], single = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:35:42.863102Z","iopub.execute_input":"2021-06-10T05:35:42.865785Z","iopub.status.idle":"2021-06-10T05:35:43.522158Z","shell.execute_reply.started":"2021-06-10T05:35:42.865746Z","shell.execute_reply":"2021-06-10T05:35:43.521064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:35:49.678695Z","iopub.execute_input":"2021-06-10T05:35:49.679164Z","iopub.status.idle":"2021-06-10T05:35:49.70551Z","shell.execute_reply.started":"2021-06-10T05:35:49.679132Z","shell.execute_reply":"2021-06-10T05:35:49.703728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import ZeroPadding2D, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\nfrom keras.layers import GlobalAveragePooling2D, MaxPooling2D\nfrom keras.models import Model, Sequential\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import regularizers","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:35:52.846057Z","iopub.execute_input":"2021-06-10T05:35:52.846439Z","iopub.status.idle":"2021-06-10T05:35:52.852782Z","shell.execute_reply.started":"2021-06-10T05:35:52.846392Z","shell.execute_reply":"2021-06-10T05:35:52.851239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_layer = Input(shape=(224,224, 3))\n\nconv = Conv2D(filters=8, kernel_size=2)(input_layer)\nconv = Conv2D(filters=16, kernel_size=2, activation='relu')(conv)\nconv = Conv2D(filters=32, kernel_size=2, activation='relu')(conv)\nconv = MaxPooling2D()(conv)\n\nconv = Conv2D(filters=64, kernel_size=2, activation='relu')(conv)\nconv = Conv2D(filters=128, kernel_size=2, activation='relu')(conv)\nconv = Conv2D(filters=512, kernel_size=2, activation='relu')(conv)\n\nconv = GlobalAveragePooling2D()(conv)\ndense = Dense(units=500, activation='relu')(conv)\ndense = Dropout(0.1)(dense)\ndense = Dense(units=100, activation='relu')(dense)\ndense = Dropout(0.1)(dense)\noutput = Dense(units=10, activation='softmax')(dense)\n\nmodel = Model(inputs=input_layer, outputs = output)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:34:52.745073Z","iopub.execute_input":"2021-06-09T07:34:52.745501Z","iopub.status.idle":"2021-06-09T07:34:52.861896Z","shell.execute_reply.started":"2021-06-09T07:34:52.745467Z","shell.execute_reply":"2021-06-09T07:34:52.860641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:34:57.358794Z","iopub.execute_input":"2021-06-09T07:34:57.35926Z","iopub.status.idle":"2021-06-09T07:34:57.376766Z","shell.execute_reply.started":"2021-06-09T07:34:57.359217Z","shell.execute_reply":"2021-06-09T07:34:57.37519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:35:05.555757Z","iopub.execute_input":"2021-06-09T07:35:05.55624Z","iopub.status.idle":"2021-06-09T07:35:05.576092Z","shell.execute_reply.started":"2021-06-09T07:35:05.556194Z","shell.execute_reply":"2021-06-09T07:35:05.574702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.load_weights('best_model_1.hdf5')\ncheckpoint = ModelCheckpoint('best_model_1.hdf5', save_best_only=True, verbose=1)\n\nhistory = model.fit_generator(train_generator, steps_per_epoch=len(train_generator),\n                    epochs=10,\n                    validation_data = val_generator,\n                    validation_steps=len(val_generator),\n                    callbacks=[checkpoint] )","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:35:11.877823Z","iopub.execute_input":"2021-06-09T07:35:11.878226Z","iopub.status.idle":"2021-06-09T10:02:45.960015Z","shell.execute_reply.started":"2021-06-09T07:35:11.878192Z","shell.execute_reply":"2021-06-09T10:02:45.95888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['val_loss'])\nplt.show()\nplt.plot(history.history['loss'])","metadata":{"execution":{"iopub.status.busy":"2021-06-09T10:02:45.962452Z","iopub.execute_input":"2021-06-09T10:02:45.963036Z","iopub.status.idle":"2021-06-09T10:02:46.290593Z","shell.execute_reply.started":"2021-06-09T10:02:45.962945Z","shell.execute_reply":"2021-06-09T10:02:46.289533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input/state-farm-distracted-driver-detection/\nimport os\n# model.load_weights('../input/best_model_1.hdf5')\n#Test Images\nbatch_index = 0\nfiles_list = os.listdir(\"../input/state-farm-distracted-driver-detection/imgs/test/\")\ndef load_test_images(batch_size=32, src='../input/state-farm-distracted-driver-detection/imgs/test/'):\n    global batch_index, files_list\n    imgs_list = files_list[batch_index: batch_index+batch_size]\n    batch_index += len(imgs_list)\n    batch_imgs = []\n    for img_name in imgs_list:\n        img = Image.open(src+img_name)\n        im = img.resize((224,224))\n        batch_imgs.append(np.array(im)/255.)\n#     plt.imshow()\n#     plt.show()\n    return np.array(batch_imgs)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T10:03:05.422859Z","iopub.execute_input":"2021-06-09T10:03:05.423307Z","iopub.status.idle":"2021-06-09T10:03:07.107681Z","shell.execute_reply.started":"2021-06-09T10:03:05.423273Z","shell.execute_reply":"2021-06-09T10:03:07.106457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test Images write\nimport sys\npreds_list = np.array([])\nbatch_index=0\nbatch_size = 32\nwhile True:\n    tst_imgs = load_test_images(batch_size=batch_size)\n    if(tst_imgs.shape[0] <= 0  ):\n        print(\"Batchsize is less : \",batch_index)\n        break\n    preds = model.predict(tst_imgs)\n    print(\"\\r {},  batch_size : {}, nth_batch/all_batch : {}/{}\".format(preds_list.shape,batch_size, batch_index, len(files_list)),end=\"\")    \n    sys.stdout.flush()\n    if len(preds_list) == 0:\n        preds_list = np.array(preds)\n    else:\n        preds_list = np.append(preds_list, preds, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T10:09:31.189448Z","iopub.execute_input":"2021-06-09T10:09:31.189887Z","iopub.status.idle":"2021-06-09T11:02:22.323404Z","shell.execute_reply.started":"2021-06-09T10:09:31.189851Z","shell.execute_reply":"2021-06-09T11:02:22.320135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices = [1,24]\nfor index in indices:\n#     display(df.iloc[index])\n    cls = np.argmax(list(df.iloc[index][1:]))\n    print(\"label : \",ac_labels[cls])\n    im_test = Image.open('../input/state-farm-distracted-driver-detection/imgs/test/'+df.iloc[index]['img'])\n    plt.imshow(np.array(im_test))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T11:02:35.766438Z","iopub.execute_input":"2021-06-09T11:02:35.767098Z","iopub.status.idle":"2021-06-09T11:02:35.813899Z","shell.execute_reply.started":"2021-06-09T11:02:35.767048Z","shell.execute_reply":"2021-06-09T11:02:35.812025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train with Transfer Learning","metadata":{}},{"cell_type":"code","source":"def load_VGG16(weights_path=None, no_top=True):\n\n    input_shape = (224, 224, 3)\n\n    #Instantiate an empty model\n    img_input = Input(shape=input_shape)   # Block 1\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n\n    # Block 2\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n\n    # Block 3\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n\n    # Block 4\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n\n    # Block 5\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n    x = GlobalAveragePooling2D()(x)\n    vmodel = Model(img_input, x, name='vgg16')\n    if weights_path is not None:\n        print(\"Weights have been loaded.\")\n        vmodel.load_weights(weights_path)\n\n    return vmodel","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:36:05.011387Z","iopub.execute_input":"2021-06-10T05:36:05.01191Z","iopub.status.idle":"2021-06-10T05:36:05.028692Z","shell.execute_reply.started":"2021-06-10T05:36:05.011865Z","shell.execute_reply":"2021-06-10T05:36:05.027447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_model_raw = load_VGG16('../input/vgg16-weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\nvgg_model = vgg_model_raw.output\n#vgg_model = Flatten()(vgg_model)\nvgg_model = Dense(5000, activation='relu',kernel_regularizer=regularizers.l2(0.00001))(vgg_model)\n#vgg_model = Dropout(0.1)(vgg_model)\n#vgg_model = Dense(1000, activation='relu')(vgg_model)\nvgg_model = Dropout(0.1)(vgg_model)\nvgg_model = Dense(500, activation='relu',kernel_regularizer=regularizers.l2(0.00001))(vgg_model)\nvgg_model = Dropout(0.1)(vgg_model)\nvgg_model = Dense(10, activation='softmax')(vgg_model)\nvgg_m = Model(inputs=vgg_model_raw.input, outputs= vgg_model)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:36:09.127165Z","iopub.execute_input":"2021-06-10T05:36:09.127697Z","iopub.status.idle":"2021-06-10T05:36:11.81348Z","shell.execute_reply.started":"2021-06-10T05:36:09.127666Z","shell.execute_reply":"2021-06-10T05:36:11.810792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_m.layers[16].get_weights()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_m.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(0.001), metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_m.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('vgg_model.h5', save_best_only=True, verbose=1)\n\nhistory = vgg_m.fit_generator(train_generator, steps_per_epoch=len(train_generator),\n                   epochs=6,\n                   validation_data = val_generator,\n                   validation_steps=len(val_generator),\n                   callbacks=[checkpoint] )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['val_loss'])\nplt.show()\nplt.plot(history.history['loss'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls\nimport os\n#model.load_weights('../input/best_model_1.hdf5')\n#Test Images\nbatch_index = 0\n#files_lst = os.listdir(\"../input/state-farm-distracted-driver-detection/test\")\nfiles_list = os.listdir(\"../input/state-farm-distracted-driver-detection/test\")\ndef load_test_images(batch_size=32, src='../input/state-farm-distracted-driver-detection/test/'):\n    global batch_index, files_list\n    imgs_list = files_list[batch_index: batch_index+batch_size]\n    batch_index += len(imgs_list)\n    batch_imgs = []\n    for img_name in imgs_list:\n        img = Image.open(src+img_name)\n        im = img.resize((224,224))\n        batch_imgs.append(np.array(im)/255.)\n#     plt.imshow()\n#     plt.show()\n    return np.array(batch_imgs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test Images write\nimport sys\npreds_list = np.array([])\nbatch_index=0\nbatch_size = 32\n\nmm_raw = load_VGG16()\n\nmm_model = mm_raw.output\nmm_model = Dense(5000, activation='relu',kernel_regularizer=regularizers.l2(0.00001))(mm_model)\nmm_model = Dropout(0.1)(mm_model)\nmm_model = Dense(500, activation='relu',kernel_regularizer=regularizers.l2(0.00001))(mm_model)\nmm_model = Dropout(0.1)(mm_model)\nmm_model = Dense(10, activation='softmax')(mm_model)\nmm = Model(inputs=vgg_model_raw.input, outputs= vgg_model)\n\nmm.load_weights('vgg_model.h5')\n\n\n\nwhile True:\n    tst_imgs = load_test_images(batch_size=batch_size)\n    if(tst_imgs.shape[0] <= 0  ):\n        print(\"Batchsize is less : \",batch_index)\n        break\n    preds = mm.predict(tst_imgs)\n    print(\"\\r {},  batch_size : {}, nth_batch/all_batch : {}/{}\".format(preds_list.shape,batch_size, batch_index, len(files_list)),end=\"\")    \n    sys.stdout.flush()\n    if len(preds_list) == 0:\n        preds_list = np.array(preds)\n    else:\n        preds_list = np.append(preds_list, preds, axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices = [10,24]\nfor index in indices:\n#     display(df.iloc[index])\n    cls = np.argmax(list(df.iloc[index][1:]))\n    print(\"label : \",ac_labels[cls])\n    im_test = Image.open('../input/state-farm-distracted-driver-detection/test/'+df.iloc[index]['img'])\n    plt.imshow(np.array(im_test))\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RESNET","metadata":{}},{"cell_type":"code","source":"import tensorflow\ntensorflow.__version__","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:55:24.045112Z","iopub.execute_input":"2021-06-10T05:55:24.045534Z","iopub.status.idle":"2021-06-10T05:55:24.051807Z","shell.execute_reply.started":"2021-06-10T05:55:24.045499Z","shell.execute_reply":"2021-06-10T05:55:24.050505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd \nfrom skimage import io\nfrom skimage import color\nfrom PIL import Image\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom dask.array.image import imread\nfrom dask import bag, threaded\nfrom dask.diagnostics import ProgressBar\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport math\n\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.layers import Flatten,Dropout\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image \nfrom keras.layers.normalization import BatchNormalization\nfrom keras import optimizers\nfrom keras.callbacks import LearningRateScheduler","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:39:35.854198Z","iopub.execute_input":"2021-06-10T05:39:35.854698Z","iopub.status.idle":"2021-06-10T05:39:39.319068Z","shell.execute_reply.started":"2021-06-10T05:39:35.854657Z","shell.execute_reply":"2021-06-10T05:39:39.317831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"driver_details = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv',na_values='na')\nprint(driver_details.head(5))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:45:11.771633Z","iopub.execute_input":"2021-06-10T05:45:11.772058Z","iopub.status.idle":"2021-06-10T05:45:11.823115Z","shell.execute_reply.started":"2021-06-10T05:45:11.772015Z","shell.execute_reply":"2021-06-10T05:45:11.821746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image = []\nimage_label = []\n\n\nfor i in range(10):\n    print('now we are in the folder C',i)\n    imgs = os.listdir(\"../input/state-farm-distracted-driver-detection/imgs/train/c\"+str(i))\n    for j in range(1300):\n    #for j in range(100):\n        img_name = \"../input/state-farm-distracted-driver-detection/imgs/train/c\"+str(i)+\"/\"+imgs[j]\n        img = cv2.imread(img_name)\n        #img = color.rgb2gray(img)\n        img = img[50:,120:-50]\n        img = cv2.resize(img,(224,224))\n        label = i\n        driver = driver_details[driver_details['img'] == imgs[j]]['subject'].values[0]\n        train_image.append([img,label,driver])\n        image_label.append(i)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:45:19.789221Z","iopub.execute_input":"2021-06-10T05:45:19.789693Z","iopub.status.idle":"2021-06-10T05:48:59.542145Z","shell.execute_reply.started":"2021-06-10T05:45:19.789663Z","shell.execute_reply":"2021-06-10T05:48:59.541033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nrandom.shuffle(train_image)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:48:59.54406Z","iopub.execute_input":"2021-06-10T05:48:59.544557Z","iopub.status.idle":"2021-06-10T05:48:59.567151Z","shell.execute_reply.started":"2021-06-10T05:48:59.544502Z","shell.execute_reply":"2021-06-10T05:48:59.565981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"driv_selected = ['p050', 'p015', 'p022', 'p056']","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:48:59.571559Z","iopub.execute_input":"2021-06-10T05:48:59.571879Z","iopub.status.idle":"2021-06-10T05:48:59.580029Z","shell.execute_reply.started":"2021-06-10T05:48:59.57185Z","shell.execute_reply":"2021-06-10T05:48:59.578901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train= []\ny_train = []\nX_test = []\ny_test = []\nD_train = []\nD_test = []\ntrue_test = []\n\nfor features,labels,drivers in train_image:\n    if drivers in driv_selected:\n        X_test.append(features)\n        y_test.append(labels)\n        D_test.append(drivers)\n        true_test.append(labels)\n    \n    else:\n        X_train.append(features)\n        y_train.append(labels)\n        D_train.append(drivers)\n    \nprint (len(X_train),len(X_test))\nprint (len(y_train),len(y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:51:24.731869Z","iopub.execute_input":"2021-06-10T05:51:24.732338Z","iopub.status.idle":"2021-06-10T05:51:24.753967Z","shell.execute_reply.started":"2021-06-10T05:51:24.732291Z","shell.execute_reply":"2021-06-10T05:51:24.752632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.array(X_train).reshape(-1,224,224,3)\nX_test = np.array(X_test).reshape(-1,224,224,3)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n\nprint (X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:51:26.935858Z","iopub.execute_input":"2021-06-10T05:51:26.936273Z","iopub.status.idle":"2021-06-10T05:51:27.725223Z","shell.execute_reply.started":"2021-06-10T05:51:26.93624Z","shell.execute_reply":"2021-06-10T05:51:27.723729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Defining the input\n\nfrom keras.layers import Input\nresnet50_input = Input(shape = (224, 224, 3), name = 'Image_input')\n\n## The RESNET model\n\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom keras.applications.resnet50 import ResNet50\n\n\n#Get the RESNET weights and layers\n\nmodel_resnet50_conv = ResNet50(weights = 'imagenet', include_top = False, input_shape = (224,224,3))\nmodel_resnet50_conv.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:51:29.086095Z","iopub.execute_input":"2021-06-10T05:51:29.086538Z","iopub.status.idle":"2021-06-10T05:51:35.421059Z","shell.execute_reply.started":"2021-06-10T05:51:29.086505Z","shell.execute_reply":"2021-06-10T05:51:35.419863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model\n\n\noutput_resnet50_conv = model_resnet50_conv(resnet50_input)\n\n#Add the fully-connected layers \n\nx = Flatten(name='flatten')(output_resnet50_conv)\n# x = Dense(4096, activation='relu', name='fc1')(x)\n# x = Dense(4096, activation='relu', name='fc2')(x)\nx = Dense(10, activation='softmax', name='predictions')(x)\n\n\n#resnet50_pretrained = Model(input = resnet50_input, output = x) Problem passing parameters\nresnet50_pretrained = Model(resnet50_input, x) # solved\n# for layer in resnet50_pretrained.layers[:2]:\n#     layer.trainable=False\n# for layer in resnet50_pretrained.layers[2:]:\n#     layer.trainable=True\n\n\nresnet50_pretrained.summary()\n\n# Compile CNN model\nadam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0)\n\n\n\ndef step_decay(epoch):\n    initial_lrate = 0.001\n    drop = 0.5\n    epochs_drop = 10.0\n    lrate = initial_lrate * math.pow(drop,  \n        math.floor((1+epoch)/epochs_drop))\n    return lrate\nlrate = LearningRateScheduler(step_decay)\n\nsgd = optimizers.SGD(lr = 0.001)\n\n\nresnet50_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:57:17.918363Z","iopub.execute_input":"2021-06-10T05:57:17.91879Z","iopub.status.idle":"2021-06-10T05:57:18.461668Z","shell.execute_reply.started":"2021-06-10T05:57:17.918744Z","shell.execute_reply":"2021-06-10T05:57:18.459346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping\n\ncheckpointer = ModelCheckpoint('resnet_weights_aug_alltrained_sgd2_setval.hdf5', verbose=1, save_best_only=True)\nearlystopper = EarlyStopping(monitor='accuracy', patience=7, verbose=1)\n\n\ndatagen = ImageDataGenerator(\n    height_shift_range=0.5,\n    width_shift_range = 0.5,\n    zoom_range = 0.5,\n    rotation_range=30\n        )\n#datagen.fit(X_train)\ndata_generator = datagen.flow(X_train, y_train, batch_size = 64)\n\n# Fits the model on batches with real-time data augmentation:\nresnet50_model = resnet50_pretrained.fit_generator(data_generator,steps_per_epoch = len(X_train) / 64, callbacks=[checkpointer, earlystopper,lrate],\n                                                            epochs = 40, verbose = 1, validation_data = (X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T05:57:31.357191Z","iopub.execute_input":"2021-06-10T05:57:31.357579Z","iopub.status.idle":"2021-06-10T07:41:06.230337Z","shell.execute_reply.started":"2021-06-10T05:57:31.357545Z","shell.execute_reply":"2021-06-10T07:41:06.226816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize = (10, 5))\naxes[0].plot(range(1, len(resnet50_pretrained.history.history['accuracy']) + 1), resnet50_pretrained.history.history['accuracy'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Accuracy')\naxes[0].plot(range(1, len(resnet50_pretrained.history.history['val_accuracy']) + 1), resnet50_pretrained.history.history['val_accuracy'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Accuracy')\naxes[0].set_xlabel('Epochs', fontsize = 14)\naxes[0].set_ylabel('Accuracy',fontsize = 14)\naxes[0].set_title('CNN Dropout Accuracy Trainig VS Testing', fontsize = 14)\naxes[0].legend(loc = 'best')\naxes[1].plot(range(1, len(resnet50_pretrained.history.history['loss']) + 1), resnet50_pretrained.history.history['loss'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Loss')\naxes[1].plot(range(1, len(resnet50_pretrained.history.history['val_loss']) + 1), resnet50_pretrained.history.history['val_loss'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Loss')\naxes[1].set_xlabel('Epochs', fontsize = 14)\naxes[1].set_ylabel('Loss',fontsize = 14)\naxes[1].set_title('CNN Dropout Loss Trainig VS Testing', fontsize = 14)\naxes[1].legend(loc = 'best')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T07:41:06.238589Z","iopub.execute_input":"2021-06-10T07:41:06.239023Z","iopub.status.idle":"2021-06-10T07:41:07.117964Z","shell.execute_reply.started":"2021-06-10T07:41:06.238975Z","shell.execute_reply":"2021-06-10T07:41:07.116574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image = []\ni = 0\nfig, ax = plt.subplots(1, 20, figsize = (50,50 ))\n\nfiles = os.listdir('../input/state-farm-distracted-driver-detection/imgs/test/')\nnums = np.random.randint(low=1, high=len(files), size=20)\nfor i in range(20):\n    print ('Image number:',i)\n    img = cv2.imread('../input/state-farm-distracted-driver-detection/imgs/test/'+files[nums[i]])\n    #img = color.rgb2gray(img)\n    img = img[50:,120:-50]\n    img = cv2.resize(img,(224,224))\n    test_image.append(img)\n    ax[i].imshow(img,cmap = 'gray')\n    plt.show","metadata":{"execution":{"iopub.status.busy":"2021-06-10T07:50:05.395988Z","iopub.execute_input":"2021-06-10T07:50:05.396366Z","iopub.status.idle":"2021-06-10T07:50:09.845082Z","shell.execute_reply.started":"2021-06-10T07:50:05.396336Z","shell.execute_reply":"2021-06-10T07:50:09.843488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = []\n\nfor img in test_image:\n    test.append(img)\n    \nresnet50_pretrained.load_weights('resnet_weights_aug_alltrained_sgd2_setval.hdf5')\n\n\ntest = np.array(test).reshape(-1,224,224,3)\nprediction = resnet50_pretrained.predict(test)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T07:50:09.847148Z","iopub.execute_input":"2021-06-10T07:50:09.847566Z","iopub.status.idle":"2021-06-10T07:50:11.585203Z","shell.execute_reply.started":"2021-06-10T07:50:09.847517Z","shell.execute_reply":"2021-06-10T07:50:11.583989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-10T07:50:11.789093Z","iopub.execute_input":"2021-06-10T07:50:11.789468Z","iopub.status.idle":"2021-06-10T07:50:11.797382Z","shell.execute_reply.started":"2021-06-10T07:50:11.78941Z","shell.execute_reply":"2021-06-10T07:50:11.796008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tags = { \"C0\": \"safe driving\",\n\"C1\": \"texting - right\",\n\"C2\": \"talking on the phone - right\",\n\"C3\": \"texting - left\",\n\"C4\": \"talking on the phone - left\",\n\"C5\": \"operating the radio\",\n\"C6\": \"drinking\",\n\"C7\": \"reaching behind\",\n\"C8\": \"hair and makeup\",\n\"C9\": \"talking to passenger\" }","metadata":{"execution":{"iopub.status.busy":"2021-06-10T07:50:17.365514Z","iopub.execute_input":"2021-06-10T07:50:17.365856Z","iopub.status.idle":"2021-06-10T07:50:17.374354Z","shell.execute_reply.started":"2021-06-10T07:50:17.365827Z","shell.execute_reply":"2021-06-10T07:50:17.373225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# labels is the image array\ni = 0\nfig, ax = plt.subplots(20, 1, figsize = (100,100))\n\nfor i in range(20):\n    ax[i].imshow(test[i].squeeze())\n    predicted_class = 'C'+str(np.where(prediction[i] == np.amax(prediction[i]))[0][0])\n    ax[i].set_title(tags[predicted_class])\n    plt.show","metadata":{"execution":{"iopub.status.busy":"2021-06-10T07:50:18.929078Z","iopub.execute_input":"2021-06-10T07:50:18.929589Z","iopub.status.idle":"2021-06-10T07:50:22.884709Z","shell.execute_reply.started":"2021-06-10T07:50:18.929557Z","shell.execute_reply":"2021-06-10T07:50:22.883271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CNN Architecture","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport glob\n\n#DATA\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import one_hot\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n#CNN\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\nfrom keras.optimizers import Adam\nfrom keras.losses import CategoricalCrossentropy\n\n#VIS\nfrom keras.utils.vis_utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:58:30.426276Z","iopub.execute_input":"2021-06-10T10:58:30.426591Z","iopub.status.idle":"2021-06-10T10:58:30.796976Z","shell.execute_reply.started":"2021-06-10T10:58:30.42656Z","shell.execute_reply":"2021-06-10T10:58:30.796134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _prepareData(path): \n    '''\n    parameters: path(STR) of the directory and flag(INT) to know if we prepare data of training or testing\n    return: (LIST) of images of the dataset and the (LIST) of labels\n    \n    For training:\n    -Read images of every directory and extract all images\n    -Resize to (128,128,3)\n    -Read the directory name and asign as a class\n    '''\n    imgsList = []\n    labels = []\n    for directory in sorted(glob.glob(os.path.join(path, '*')), key = lambda k: k.split(\"/\")[-1]):\n            for imgs in glob.glob(os.path.join(directory,'*.jpg')):\n                img_cv = cv2.imread(imgs)\n                img_cv_r = cv2.resize(img_cv,(128,128))\n                imgsList.append(img_cv_r)\n                labels.append(int(directory.split(\"/\")[-1].replace('c','')))\n    \n    X_Train, X_Test, Y_Train, Y_Test =  train_test_split(imgsList,labels, test_size = 0.2)\n    Y_Train = tf.keras.utils.to_categorical(Y_Train, num_classes=10)\n    Y_Test = tf.keras.utils.to_categorical(Y_Test, num_classes=10)\n\n    return np.array(X_Train), np.array(X_Test), Y_Train, Y_Test","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:58:32.555068Z","iopub.execute_input":"2021-06-10T10:58:32.555392Z","iopub.status.idle":"2021-06-10T10:58:32.566946Z","shell.execute_reply.started":"2021-06-10T10:58:32.555362Z","shell.execute_reply":"2021-06-10T10:58:32.565089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Paths\npathTrain_Images = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train/\"\npathPropagate_Images =  \"/kaggle/input/state-farm-distracted-driver-detection/imgs/test/\"\n\n#List of Images for Train and Test\nX_Train, X_Test, Y_Train, Y_Test = _prepareData(pathTrain_Images)\n\nprint(\"Size X_Train: {}, Size Y_Train: {}\".format(len(X_Train),len(Y_Train)))\nprint(\"Size X_Test: {}, Size Y_Test: {}\".format(len(X_Test),len(Y_Test)))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:58:35.002863Z","iopub.execute_input":"2021-06-10T10:58:35.003557Z","iopub.status.idle":"2021-06-10T11:00:34.783393Z","shell.execute_reply.started":"2021-06-10T10:58:35.003513Z","shell.execute_reply":"2021-06-10T11:00:34.781321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(X_Train))\nprint(X_Train[202].shape)\nim = X_Train[202]\nRGB_im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\nplt.imshow(RGB_im)\nplt.show()\nprint(\"Class: {}\".format(Y_Train[202]))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:00:34.784845Z","iopub.execute_input":"2021-06-10T11:00:34.785167Z","iopub.status.idle":"2021-06-10T11:00:34.943226Z","shell.execute_reply.started":"2021-06-10T11:00:34.78513Z","shell.execute_reply":"2021-06-10T11:00:34.94245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_file = pd.read_csv(\"/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv\")\ndata_classes = data_file.loc[:,['classname','img']].groupby(by='classname').count().reset_index()\n\ndata_x = list(pd.unique(data_file['classname']))\ndata_y =list(data_classes['img'])\n\n# Parámetros de ploteo (Se va a generar un plot diferente para cada Clase)\nplt.rcParams.update({'font.size': 22})\nplt.figure(figsize=(30,10))\nplt.bar(data_x, data_y, color=['cornflowerblue', 'lightblue', 'steelblue'])  \nplt.ylabel('Count classes')\nplt.title('Classes')\nplt.xticks(rotation=45)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:00:34.944813Z","iopub.execute_input":"2021-06-10T11:00:34.945311Z","iopub.status.idle":"2021-06-10T11:00:35.162652Z","shell.execute_reply.started":"2021-06-10T11:00:34.945273Z","shell.execute_reply":"2021-06-10T11:00:35.161649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.Sequential()\n\nmodel.add(keras.layers.InputLayer(\n    input_shape=(128, 128, 3)\n))\n\nmodel.add(\n    keras.layers.Conv2D(\n        filters=32,\n        kernel_size=(5,5),\n        strides = (1,1),\n        padding='same',\n        activation='relu',\n        name='Conv_1'))\n\nmodel.add(\n    keras.layers.MaxPool2D(\n        pool_size = (2,2),\n        name = 'Pool_1'))#Image_size: 32*64*64(32 filters,image_size 64*64)\n\nmodel.add(\n    keras.layers.Conv2D(\n        filters = 64,\n        kernel_size = (5,5),\n        strides = (1,1),\n        padding = 'same',\n        activation = 'relu',\n        name = 'Conv_2'))\n\nmodel.add(\n    keras.layers.MaxPool2D(\n        pool_size = (2,2),\n        name = 'Pool_2'))#Image_size: 64*32*32(64 filters,image_size 32*32)\n\nmodel.add(\n    keras.layers.Conv2D(\n        filters = 128,\n        kernel_size = (5,5),\n        strides = (1,1),\n        padding = 'same',\n        activation = 'relu',\n        name = 'Conv_3'))\n\nmodel.add(\n    keras.layers.MaxPool2D(\n        pool_size = (2,2),\n        name = 'Pool_3'))#Image_size: 128*16*16(128 filters,image_size 16*16)\n\nmodel.add(\n    keras.layers.Conv2D(\n        filters = 256,\n        kernel_size = (5,5),\n        strides = (1,1),\n        padding = 'same',\n        activation = 'relu',\n        name = 'Conv_4'))\n\nmodel.add(\n    keras.layers.MaxPool2D(\n        pool_size = (2,2),\n        name = 'Pool_4'))#Image_size: 256*8*8(256 filters,image_size 8*8)\n\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(units=1024, activation='relu',name = 'fc_1'))\nmodel.add(keras.layers.Dropout(rate=0.2))\nmodel.add(keras.layers.Dense(units=512, activation='relu',name = 'fc_2'))\nmodel.add(keras.layers.Dense(units=10,activation='softmax',name = 'fc_3'))\n\nmodel.save('/tmp/model')\n#model.save('../input/result1')\n#model.compute_output_shape(input_shape=(256,8,8,1))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:04:21.536138Z","iopub.execute_input":"2021-06-10T11:04:21.536523Z","iopub.status.idle":"2021-06-10T11:04:31.655677Z","shell.execute_reply.started":"2021-06-10T11:04:21.53649Z","shell.execute_reply":"2021-06-10T11:04:31.653164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(1)\n#model.build(input_shape=(None,128,128,3))\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False), metrics = ['accuracy'])\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2021-06-10T11:00:45.802621Z","iopub.status.idle":"2021-06-10T11:00:45.803358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x = X_Train, y=Y_Train,epochs =18, batch_size = 500, verbose = 1, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:08:45.520442Z","iopub.execute_input":"2021-06-10T10:08:45.520784Z","iopub.status.idle":"2021-06-10T10:35:42.235677Z","shell.execute_reply.started":"2021-06-10T10:08:45.520746Z","shell.execute_reply":"2021-06-10T10:35:42.234891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(X_Test, Y_Test, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:37:51.984565Z","iopub.execute_input":"2021-06-10T10:37:51.984939Z","iopub.status.idle":"2021-06-10T10:38:08.896627Z","shell.execute_reply.started":"2021-06-10T10:37:51.984907Z","shell.execute_reply":"2021-06-10T10:38:08.895797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\n\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\n#plt.ylim([0.9,1])\nplt.legend(['train','test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\n\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\n#plt.ylim([0,.4])\nplt.legend(['train','test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:38:08.898096Z","iopub.execute_input":"2021-06-10T10:38:08.898425Z","iopub.status.idle":"2021-06-10T10:38:09.128194Z","shell.execute_reply.started":"2021-06-10T10:38:08.898387Z","shell.execute_reply":"2021-06-10T10:38:09.127236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\nmodel.save_weights('./Train_weights_1.h5', overwrite = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:39:58.621503Z","iopub.execute_input":"2021-06-10T10:39:58.621867Z","iopub.status.idle":"2021-06-10T10:39:58.819296Z","shell.execute_reply.started":"2021-06-10T10:39:58.621828Z","shell.execute_reply":"2021-06-10T10:39:58.818229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('./new_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:57:59.498551Z","iopub.execute_input":"2021-06-10T10:57:59.498914Z","iopub.status.idle":"2021-06-10T10:57:59.519726Z","shell.execute_reply.started":"2021-06-10T10:57:59.498881Z","shell.execute_reply":"2021-06-10T10:57:59.51857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('./Train_weights_1.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:40:01.252771Z","iopub.execute_input":"2021-06-10T10:40:01.253088Z","iopub.status.idle":"2021-06-10T10:40:01.309593Z","shell.execute_reply.started":"2021-06-10T10:40:01.25306Z","shell.execute_reply":"2021-06-10T10:40:01.308779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(model,\"model.png\",show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:40:08.673762Z","iopub.execute_input":"2021-06-10T10:40:08.674086Z","iopub.status.idle":"2021-06-10T10:40:08.946608Z","shell.execute_reply.started":"2021-06-10T10:40:08.674057Z","shell.execute_reply":"2021-06-10T10:40:08.945691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport os\nimport numpy as np\nimport cv2\n\ntest_image = []\ni = 0\nfig, ax = plt.subplots(1, 20, figsize = (50,50 ))\n\nfiles = os.listdir('../input/state-farm-distracted-driver-detection/imgs/test/')\nnums = np.random.randint(low=1, high=len(files), size=20)\nfor i in range(20):\n    print ('Image number:',i)\n    img = cv2.imread('../input/state-farm-distracted-driver-detection/imgs/test/'+files[nums[i]])\n    #img = color.rgb2gray(img)\n    img = img[50:,120:-50]\n    img = cv2.resize(img,(224,224))\n    test_image.append(img)\n    ax[i].imshow(img,cmap = 'gray')\n    plt.show","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:48:44.005498Z","iopub.execute_input":"2021-06-10T10:48:44.00585Z","iopub.status.idle":"2021-06-10T10:48:46.334954Z","shell.execute_reply.started":"2021-06-10T10:48:44.005818Z","shell.execute_reply":"2021-06-10T10:48:46.334028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load json and create model\njson_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")\n\n\nfrom tensorflow.keras.models import load_model\nmodel = load_model('./Train_weights_1.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:50:56.466914Z","iopub.execute_input":"2021-06-10T10:50:56.46723Z","iopub.status.idle":"2021-06-10T10:50:56.493011Z","shell.execute_reply.started":"2021-06-10T10:50:56.467202Z","shell.execute_reply":"2021-06-10T10:50:56.491444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = []\n\nfor img in test_image:\n    test.append(img)\n    \n#model.load_weights('./Train_weights_1.h5')\n\n\ntest = np.array(test).reshape(-1,224,224,3)\nprediction = model.predict(test)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:49:02.337368Z","iopub.execute_input":"2021-06-10T10:49:02.337683Z","iopub.status.idle":"2021-06-10T10:49:02.353331Z","shell.execute_reply.started":"2021-06-10T10:49:02.337652Z","shell.execute_reply":"2021-06-10T10:49:02.351924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}